---
title: "Homework 4"
author: "Mel Zarate"
date: "10/23/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

[1] Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:

Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test().

The function should contain a check for the rules of thumb we have talked about (n∗p>5 and n∗(1−p)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.
```{r}
#first the one sample- normality guidelines:
z.test <- function(p1,n1,p0,p2=NULL,n2=NULL,conf.level=0.95,alternative="two.sided") {
   if(p1 == 0){
    return(0)}
    else {if((n1 * p1 < 5) | (n1 * (1-p1) > 5)){
          return(c("Warning: Not Normal", (p1-p0) / sqrt((p0 * (1-p0))/n1)))}
          else(return((p1-p0) / sqrt((p0 * (1-p0))/n1)))}
}
#now a function for two sample test
z.test.2 <- function(p1,n1,p0,p2,n2,conf.level=0.95,alternative="two.sided") {
   if(p1 == 0){
    return(0)}
    else {if((n1 * p1 < 5) | (n1 * (1-p1) > 5)){
          return(c("Warning: Not Normal", (p1-p0) / sqrt((p0 * (1-p0))/n1)))}
          else(return((p1-p0) / sqrt((p0 * (1-p0))/n1)))}
  #for second sample
  if(p2 == 0){
    return(0)}
    else {if((n2 * p2 < 5) | (n2 * (1-p2) > 5)){
          return(c("Warning: Not Normal", (p2-p0) / sqrt((p0 * (1-p0))/n2)))}
          else(return((p2-p0) / sqrt((p0 * (1-p0))/n2)))}
}
```


When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, the same as in the use of x and y in the function t.test().
trying this with hypothetical values: 
```{r}
#one sample: sample proportion is 10%, size is 100, expected populaiton proportion is 25%
z.test(p1=.10,n1=100,p0=.25,p2=NULL,n2=NULL,conf.level=0.95,alternative="two.sided")
#yay it worked! not normal but at least it told me. 
#two sample test: 
z.test.2(p1=.10,n1=100,p0=.25,p2=.15,n2=50,conf.level=0.95,alternative="two.sided")
```
I'm not sure why I'm getting the same value here, or what that value is even supposed to represent. 

The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.
#Howwww do I get all of this?!?


[2] The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. 
Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).

Download the data
```{r}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall19/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
```

For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):

First lets plot the two variables. 
```{r}
plot(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
```

Residuals don't look to normal; this is kind of hard to look at. But it looks like it *may* be exponentially increasing? 

make the model: 
```{r}
model <- lm(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
summary(model)
```
R squared:  0.4928 not too great but shows *some* correlation. 

Let's look if we are fitting assumptions of a linear model
```{r}
plot(model)
```
.... that kind of looks like garbage. 

So it definitely is not linear. 

##Data Transformation
Now lets take the log of every variable to smooth over that exponential difference 
```{r}
d$logMaxLongevity_m <- log(d$MaxLongevity_m)
d$logBrain_Size_Species_Mean <- log(d$Brain_Size_Species_Mean)
plot(data = d, logMaxLongevity_m ~ logBrain_Size_Species_Mean)
model <- lm(data = d, logMaxLongevity_m ~ logBrain_Size_Species_Mean)
summary(model)
plot(model)
```
R squared is a little better, and the plot is definitely a bit better.

the car plot (for the pretty Q-Q): 
```{r}
qqPlot(model$residuals)
```

Everything is in the confidence intervals!

Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. 

So this is what I want to run a line through and find the slope: 
```{r}
library(ggplot2)
g <- ggplot(data = d, aes(x = d$logBrain_Size_Species_Mean, y = d$logMaxLongevity_m)) + geom_point()
g
```

```{r}
b <- d$logBrain_Size_Species_Mean
l <- d$logMaxLongevity_m
beta1 <- cor(b,l)/var(b)
beta1
```
I don't know what this is giving me NA, so I'm going to try to look at it with the lm() function. 

```{r}
m <- lm(l ~ b)
m
```
So this means that the slope is 0.23!!! (And I definitely could have just looked at this before)

Also, find a 90 percent CI for the slope (β1) parameter.
Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

To do this part, I am going to use the lmodel2 package
#do I do this for the logged variables as well? 
```{r}
library(lmodel2)  # load the lmodel2 package
mII <- lmodel2(MaxLongevity_m ~ Brain_Size_Species_Mean, data = d, range.y = "relative", range.x = "relative", 
    nperm = 1000)
mII
```
Doesn't give me regression results or confidence intervals, so I'm going to try it with the logged variables: 

```{r}
mII <- lmodel2(logMaxLongevity_m ~ logBrain_Size_Species_Mean, data = d, range.y = "relative", range.x = "relative", 
    nperm = 1000)
mII
```
Still no results??? Let's see if anything will plot 

```{r}
plot(mII, "OLS") #plotting results of tests ran by lmodel2
plot(mII, "RMA")
plot(mII, "SMA")
```
They all look about the same. 

Plotting the CIs and PIs:

```{r}
m <- lm(data = d, logMaxLongevity_m ~ logBrain_Size_Species_Mean)
h_hat <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = d$logBrain_Size_Species_Mean))
df <- data.frame(cbind(d$logBrain_Size_Species_Mean, d$logMaxLongevity_m, h_hat))
names(df) <- c("x", "y", "yhat")
head(df)
```
Use this object for CI
```{r}
ci <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = d$logBrain_Size_Species_Mean), interval = "confidence", 
    level = 0.90)  # for a vector of values
head(ci)
```
Use that to create a dataframe to plot 
```{r}
df <- cbind(df, ci)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr")
head(df)
```
NAs for some values in these???

This will have upper and lower confidence intervals: 
```{r}
g <- ggplot(data = df, aes(x = x, y = y))
g <- g + geom_point(alpha = 1/2)
g <- g + geom_line(aes(x = x, y = CIfit), colour = "black")
g <- g + geom_line(aes(x = x, y = CIlwr), colour = "blue")
g <- g + geom_line(aes(x = x, y = CIupr), colour = "blue")
g
```
(I did this first with the normal variables instead of the log variables and this looks MUCH better)

Add the PI bands by making a data frame of values:
```{r}
pi <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = d$logBrain_Size_Species_Mean), interval = "prediction", 
    level = 0.90)  # for a vector of values
head(pi)
df <- cbind(df, pi) #make them a dataframe
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", 
    "PIupr")
head(df)
```

Put it all together: 
```{r}
g <- g + geom_line(data = df, aes(x = x, y = PIlwr), colour = "red")
g <- g + geom_line(data = df, aes(x = x, y = PIupr), colour = "red")
g
```


Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. 

```{r}
pi <- predict(m, newdata = data.frame(logBrain_Size_Species_Mean = 800), interval = "prediction", 
    level = 0.90)  # for a single value
pi
```
# estimate: 192.1986, lower, upper: 168.6955, 215.7017

Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not? By looking at the plot of the model itself, not really. There is a good amount outside of both the CI and PI ranges. 

Looking at your two models, which do you think is better? Why?

1. Proceeding with the CI, I wasn't sure if I should still be using the logged variables. 
2. I tried two ways that I thought would give me the confidence intervals. lmodel2 tests are not giving me any regression or confidence interval results. Then I used the predict() function. 
3. Conceptually, I don't understand the difference in CI for the sample and for a species with a certain brain weight. 
4. Which two models are we looking at?
5. Writing a function: lost.